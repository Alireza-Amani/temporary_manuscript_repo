{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b952d2db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:32:50.319637Z",
     "start_time": "2022-11-04T16:32:50.314563Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Notes\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "Introductory notes</p>\n",
    "<hr style=\"height:0.3vw\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316368d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T16:34:01.151245Z",
     "start_time": "2022-11-04T16:34:01.145260Z"
    },
    "hidden": true
   },
   "source": [
    "<hr><br> \n",
    "<p style=\"font-size: 1.1em; line-height: 2em\">\n",
    "    This notebook hosts the code that was /can-be-used to create and run <br>\n",
    "    the two ensembles of SVS model that were discussed in the manuscript.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.1em; line-height: 2vw\">\n",
    "    The codes included in this notebook can perform the following tasks:\n",
    "    <ul style=\"font-size: 1.1em; line-height: 2em\">\n",
    "        <li>Run a single instance of SVS model</li>\n",
    "        <li>Create and run the 'SVS-lab' ensemble</li>\n",
    "        <li>Create and run the 'SVS-def' ensemble</li>\n",
    "    </ul>\n",
    "    \n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<p style=\"font-size: 1.1em; line-height: 2em\">\n",
    "Note that every code cell of this notebook is self-sufficient. That is, one only needs to run the cell to get the expected output.\n",
    "<br>However, you might need to use `if __name__ == \"__main__\"`. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546a008",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr><br> \n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "<b>Important notes</b> <br> The official supporting/guiding documents concerning the SVS land-surface model \n",
    "are provided at this <a href=\"https://wiki.usask.ca/display/MESH/Soil-Vegetation-Snow+%28SVS%29+-+Version+1\">address</a>. \n",
    "<br>\n",
    "Read the <a href=\"https://wiki.usask.ca/display/MESH/How+to+configure+MESH-SVS+for+point+mode+%281D%29%2C+including+SVS2\">sample configuration</a> on how to setup an SVS (version 1) run in point-mode.\n",
    "    \n",
    "The source code of the SVS1 was cloned from its GitHub repository at the following \n",
    "<a href=\"https://github.com/VVionnet/MESH_SVS/commit/627a369ead25d470810e9350f7cfca792e7d594b\"> commit </a> \n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "    <span>Necessary steps for running SVS1 in point-mode</span>\n",
    "    <ol style=\"font-size: 1.2em; line-height: 2em\">\n",
    "        <li>Compile the source code and obtain the executable file</li>\n",
    "        <li>Create the required input files</li>\n",
    "        <ul>\n",
    "            <li>basin_forcing.met</li>\n",
    "            <li>MESH_parameters.txt</li>\n",
    "            <li>MESH_input_soil_levels.txt</li>\n",
    "            <li>MESH_input_run_options.ini</li>\n",
    "            <li>An output folder</li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "</p>\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "The Python class only takes care of the second step. In the following lines some explanations are provided\n",
    "<br> regarding the information that one needs to pass to the SVSModel class, so that the class can create\n",
    "<br> the needed input files, and subsequently run the model in point-mode.\n",
    "<br><br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "    <b>Meteorological data</b><br>\n",
    "    basin_forcing.met is the file that SVS reads to access the hourly meteorological variables needed to run the model.<br>\n",
    "    We need to create a dataframe (.csv file) each row of which contains values for:\n",
    "    <ul style=\"font-size: 1.2em; line-height: 2em\">\n",
    "        <li>UTC datetime</li>\n",
    "        <li>air temperature (°C)</li>\n",
    "        <li>precipitation volume (mm)</li>\n",
    "        <li>wind speed (m/s)</li>\n",
    "        <li>atmospheric pressure (Pa)</li>\n",
    "        <li>specific humidity (kg/kg)</li>\n",
    "        <li>shortwave radiation (w/m2)</li>\n",
    "        <li>longwave radiation (w/m2)</li>\n",
    "    </ul>\n",
    "    <br><br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "    SVSModel will take care of converting the dataframe into a basin_forcing.met file. <br>\n",
    "    For this process to happen, one should provide the path to the dataframe holding the meteo data\n",
    "    <br> also, the label of the columns inside the said dataframe corresponding to the required forcing varaibles:\n",
    "    \n",
    "<pre><code>#Example\n",
    "path_to_met_data = \"./dir1/dir2/data.csv\"\n",
    "dict_met_col_labels = dict(\n",
    "    utc_dtime=\"dt_utc\", air_temperature=\"Air temperature (°C)\", \n",
    "    precipitation=\"Precipitation (mm)\", wind_speed=\"Wind speed (m.s-1)\", \n",
    "    atmospheric_pressure=\"Atmospheric pressure (Pa)\", \n",
    "    shortwave_radiation=\"Shortwave radiation (W.m-2)\", \n",
    "    longwave_radiation=\"Longwave radiation (W.m-2)\", \n",
    "    specific_humidity=\"Specific humidity (kg.kg-1)\"\n",
    ")</code>\n",
    "</pre>\n",
    "In this dictionary, we only need to change the values, not the keys. \n",
    "</p>\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "<b>Parametric data</b><br>\n",
    "To run SVS, we need to define one or more soil layers with their corresponding thickness in the \n",
    "MESH_input_soil_levels.txt. <br> For each of these layers, we need to provide several properties inside the MESH_parameters.txt file.<br>\n",
    "And lastly, MESH_input_run_options.ini is the place to set options, such as start and end time steps.  <br>\n",
    "SVSModel needs certain inputs to be able to take care of the above-mentioned tasks. Some of these inputs are to be provided <br>\n",
    "inside the script, and some of them are expected to exist in a dataframe (.csv file). An example of this dataframe for our case <br>\n",
    "(point-scale) is provided below (first three rows): <br>\n",
    "    \n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>layer_nr</th>\n",
    "      <th>thickness_m</th>\n",
    "      <th>ends_at_m</th>\n",
    "      <th>sensor</th>\n",
    "      <th>soil_type</th>\n",
    "      <th>sand</th>\n",
    "      <th>clay</th>\n",
    "      <th>Wsat</th>\n",
    "      <th>Wfc</th>\n",
    "      <th>Wwilt</th>\n",
    "      <th>Ksat</th>\n",
    "      <th>Psi_sat</th>\n",
    "      <th>bcoef</th>\n",
    "      <th>dry_density</th>\n",
    "      <th>enclosure_slope</th>\n",
    "      <th>observed_forcing</th>\n",
    "      <th>zusl</th>\n",
    "      <th>ztsl</th>\n",
    "      <th>draindens</th>\n",
    "      <th>deglat</th>\n",
    "      <th>deglng</th>\n",
    "      <th>vf_type</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1</td>\n",
    "      <td>0.025</td>\n",
    "      <td>0.025</td>\n",
    "      <td>No sensor</td>\n",
    "      <td>s1</td>\n",
    "      <td>78.48</td>\n",
    "      <td>5.59</td>\n",
    "      <td>0.3269</td>\n",
    "      <td>0.0579</td>\n",
    "      <td>0.0083</td>\n",
    "      <td>0.000023</td>\n",
    "      <td>0.307</td>\n",
    "      <td>2.32</td>\n",
    "      <td>1603.03</td>\n",
    "      <td>0.02</td>\n",
    "      <td>height</td>\n",
    "      <td>10.0</td>\n",
    "      <td>1.5</td>\n",
    "      <td>0.0</td>\n",
    "      <td>45.82</td>\n",
    "      <td>-72.37</td>\n",
    "      <td>13</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2</td>\n",
    "      <td>0.025</td>\n",
    "      <td>0.050</td>\n",
    "      <td>No sensor</td>\n",
    "      <td>s1</td>\n",
    "      <td>78.48</td>\n",
    "      <td>5.59</td>\n",
    "      <td>0.3269</td>\n",
    "      <td>0.0579</td>\n",
    "      <td>0.0083</td>\n",
    "      <td>0.000023</td>\n",
    "      <td>0.307</td>\n",
    "      <td>2.32</td>\n",
    "      <td>1603.03</td>\n",
    "      <td>0.02</td>\n",
    "      <td>height</td>\n",
    "      <td>10.0</td>\n",
    "      <td>1.5</td>\n",
    "      <td>0.0</td>\n",
    "      <td>45.82</td>\n",
    "      <td>-72.37</td>\n",
    "      <td>13</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>3</td>\n",
    "      <td>0.050</td>\n",
    "      <td>0.100</td>\n",
    "      <td>sensor_75mm</td>\n",
    "      <td>s1</td>\n",
    "      <td>78.48</td>\n",
    "      <td>5.59</td>\n",
    "      <td>0.3269</td>\n",
    "      <td>0.0579</td>\n",
    "      <td>0.0083</td>\n",
    "      <td>0.000023</td>\n",
    "      <td>0.307</td>\n",
    "      <td>2.32</td>\n",
    "      <td>1603.03</td>\n",
    "      <td>0.02</td>\n",
    "      <td>height</td>\n",
    "      <td>10.0</td>\n",
    "      <td>1.5</td>\n",
    "      <td>0.0</td>\n",
    "      <td>45.82</td>\n",
    "      <td>-72.37</td>\n",
    "      <td>13</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "One needs to manually create such dataframe and provide its path in the scripts. <br>\n",
    "Some note about creating this dataframe: <br>\n",
    "The 'layer_nr', 'sensor', 'soil_type' are not needed, they are simply additional information we wanted to store.<br>\n",
    "The 'ends_at_m' column contain the depth at which the soil layer ends, in meter. <br>\n",
    "'Ksat', 'Psi_sat' are the soil hydraulic conductivity and suction at saturation. <br>\n",
    "'bcoef' is the coefficient in the default SWRC model used in SVS. <br>\n",
    "'dry_density' is the soil dry density in kg/m3. <br>\n",
    "'enclosure_slope' is the slope of the modelled soil column. <br>\n",
    "'vf_type' is the integer denoting the type of the vegetation cover, please refer to the documentation for the look-up table.\n",
    "<br>\n",
    "The rest of the parameters, including the static properties (i.e. not changing with the soil layer), are explained in the sample configuration. <br>\n",
    "Beside providing a path to this dataframe, one needs to set values for the keys of a dictionary defined in the sample code:\n",
    "<br>\n",
    "<pre><code># an example \n",
    "dict_param_col_labels = dict(\n",
    "# parameters for each soil layer\n",
    "sand=\"sand\", clay=\"clay\", wsat=\"Wsat\", wfc=\"Wfc\", wwilt=\"Wwilt\",\n",
    "psisat=\"Psi_sat\", bcoef=\"bcoef\", ksat=\"Ksat\", rhosoil=\"dry_density\",\n",
    "# scalar parameters\n",
    "slop=\"enclosure_slope\", observed_forcing=\"observed_forcing\", zusl=\"zusl\",\n",
    "ztsl=\"ztsl\", deglat=\"deglat\", deglng=\"deglng\", vf_type=\"vf_type\",\n",
    "draindens=\"draindens\"\n",
    ")</code></pre>\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "The last part of the provided sample scripts that might need further explanations, beside the extensive comments, is the <br>\n",
    "dictionary that the user needs to set the values of the defined keys. These are some of the SVS internal parameters that are <br>\n",
    "read from the MESH_parameters.txt by default or as part of the modified source code used in this research.\n",
    "<br>\n",
    "<pre><code># an example \n",
    "ddict_model_params = dict(\n",
    "    SCHMSOL=\"SVS\", lsoil_freezing_svs1=\".true.\", soiltext=\"NIL\",\n",
    "    read_user_parameters=1, water_ponding=0, KFICE=0, OPT_SNOW=2, OPT_FRAC=1,\n",
    "    OPT_LIQWAT=1, WAT_REDIS=0, save_minutes_csv=0, tperm=283.15,\n",
    "    user_wfcdp=0.32\n",
    ")</code></pre><br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "The parameters that are not mentioned in the official doc, will be explained below.<br>\n",
    "'user_wfcdp' is the trigger moisture. The trigger moisture is the soil volumetric water content threshold value for the last layer,\n",
    "<br> before which the model will not calculate any vertical drainage from the last layer. <br>\n",
    "'KFICE' and 'WAT_REDIS' are explained in the 'hydro_svs.F90' subroutine, in the source code. <br>\n",
    "'OPT_SNOW', 'OPT_FRAC', and 'OPT_LIQWAT' are explained in the 'soil_freezing.F90' subroutine, in the source code.<br>\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "Any other needed data/information to instantiate the SVSModel class is mentioned in the sample codes or the docstrings.<br>\n",
    "Nevertheless, you are always welcome to contact us.\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "<b>Output variables</b><br>\n",
    "The daily aggregated output variables of the SVS runs are stored as an attribute of the SVSModel instance. <br>\n",
    "There are a few columns, hence variables, that we introduce here, the rest can be figured out by reading the official doc. <br>\n",
    "The first few rows, and columns, of an example of a 'dfdaily_out' attribute: <br>\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>DRAI</th>\n",
    "      <th>ET</th>\n",
    "      <th>PCP</th>\n",
    "      <th>OVFLW</th>\n",
    "      <th>date</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>0.0</td>\n",
    "      <td>3.1570</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>2018-07-01</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>0.0</td>\n",
    "      <td>4.7517</td>\n",
    "      <td>16.7</td>\n",
    "      <td>0.0</td>\n",
    "      <td>2018-07-02</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "* 'DRAI': vertical drainage (percolation) from the bottom of the last layer <br>\n",
    "* 'ET': evapotranspiration <br>\n",
    "* 'PCP': precipitation <br>\n",
    "* 'OVFLW': overlandflow <br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "<b>Sample codes</b><br>\n",
    "In this notebook, we have provided codes to run SVS, single or as an ensemble (based on the manuscript), for the L1 cover. <br>\n",
    "The required dataframes (explained above) are included in the 'data' folder for the rest of the covers. <br>\n",
    "To perform the same operations for the other covers, simply copy the sample codes and do the following modifications: <br>\n",
    "- update the path to the dataframe that contains the parameter info for the respective cover.\n",
    "- update the path to the working dir, which is created specifically for the cover (case-study) you are trying to run the model for.\n",
    "- (For ensembles) update the lower and upper bound of the trigger moisture values. \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "<b>Python and compiler versions</b><br>\n",
    "All of the Python codes were written and tested using:\n",
    "<br>\n",
    "<pre><code>\n",
    "import sys\n",
    "sys.version\n",
    ">>> '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:54) [Clang 13.0.1 ]'\n",
    "</code></pre><br>\n",
    "</p>\n",
    "<p style=\"font-size: 1.2em; line-height: 2em\">\n",
    "The codes are expected to run without any problem with Python 3.8 or higher. <br>\n",
    "Please do consult the official doc on how to compile the source code, that being said, we have used <br>\n",
    "gfortran 8.5 on Mac OS, and gfortran 9 on a Windows machine.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a8a26",
   "metadata": {},
   "source": [
    "# Run a single SVS instance\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Instantiate an SVS model object and run it for the soil covers presented in the manuscript\n",
    "</p>\n",
    "<hr style=\"height:0.3vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3ad94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T23:32:21.110696Z",
     "start_time": "2022-11-04T23:32:21.110674Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## L1 cover, laboratory parameters\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Run an instance of SVS model for the L1 cover, parameterized using the laboratory-obtained values for the <br>\n",
    "    soil properties.\n",
    "</p>\n",
    "<hr style=\"height:0.1vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70c39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T15:56:26.852965Z",
     "start_time": "2022-11-08T15:55:16.180583Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <<< imports >>> -----------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from svs_model import SVSModel\n",
    "from prep_svs import ModelInputData\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< variable definition >>> -----------------------------------------------\n",
    "\n",
    "# the below-defined paths are relative to the current working dir before this\n",
    "# cell is run. It might be better to define all of them as absolute path. \n",
    "dict_path = {\n",
    "    # existing dir in which a folder will be created to host the SVS-run files\n",
    "    \"work_dir\": Path(\"./SVS\"),\n",
    "    \n",
    "    # path to the SVS executable file\n",
    "    \"svs_exec\": Path(\"./SVS/MESH_SVS_6p1\"),\n",
    "\n",
    "    \n",
    "    # path to the dataframe holding required info about the cover\n",
    "    \"cover_info\": Path(\"data/SVS/L1_params.csv\"),\n",
    "    \n",
    "    # path to the dataframe holding hourly forcing variables\n",
    "    \"met_data\": Path(\"./data/SVS/hourly_SVS_meteo.csv\"),\n",
    "    \n",
    "    # name of the folder created inside `work_dir` to host SVS-run files\n",
    "    \"host_folder_name\": \"run_single_L1\",\n",
    "    \n",
    "    # provide a path here if you wish to save the daily output\n",
    "    \"save_results\": \"\" \n",
    "}\n",
    "\n",
    "# labels of the required columns in the meteo dataframe located at \n",
    "# `dict_path['met_data']`. \n",
    "# the required columns correspond to the required meteorological variables\n",
    "# needed to run SVS, plus the data-time column (tz: UTC)\n",
    "dict_met_col_labels = dict(\n",
    "    utc_dtime=\"dt_utc\", air_temperature=\"Air temperature (°C)\", \n",
    "    precipitation=\"Precipitation (mm)\", wind_speed=\"Wind speed (m.s-1)\", \n",
    "    atmospheric_pressure=\"Atmospheric pressure (Pa)\", \n",
    "    shortwave_radiation=\"Shortwave radiation (W.m-2)\", \n",
    "    longwave_radiation=\"Longwave radiation (W.m-2)\", \n",
    "    specific_humidity=\"Specific humidity (kg.kg-1)\",\n",
    "    relative_humidity=\"Relative humidity (%)\" # needed only for precip phase \n",
    ")\n",
    "\n",
    "# The label of the columns, inside the dataframe holding the cover's info\n",
    "# located at `dict_path['cover_info']`, corresponding to the parameters that\n",
    "# are required to create the MESH_parameters.txt file. \n",
    "\n",
    "# e.g. the values for the `sand` parameter in the MESH_parameters.txt file is \n",
    "# stored in a column named `sand` in the dataframe\n",
    "dict_param_col_labels = dict(\n",
    "    # parameters for each soil layer\n",
    "    sand=\"sand\", clay=\"clay\", wsat=\"Wsat\", wfc=\"Wfc\", wwilt=\"Wwilt\",\n",
    "    psisat=\"Psi_sat\", bcoef=\"bcoef\", ksat=\"Ksat\", rhosoil=\"dry_density\",\n",
    "    \n",
    "    # scalar parameters\n",
    "    slop=\"enclosure_slope\", observed_forcing=\"observed_forcing\", zusl=\"zusl\",\n",
    "    ztsl=\"ztsl\", deglat=\"deglat\", deglng=\"deglng\", vf_type=\"vf_type\",\n",
    "    draindens=\"draindens\"\n",
    ") \n",
    "\n",
    "# The values for some of the model parameters that are read from\n",
    "# the MESH_parameters.txt file. \n",
    "dict_model_params = dict(\n",
    "    SCHMSOL=\"SVS\", lsoil_freezing_svs1=\".true.\", soiltext=\"NIL\",\n",
    "    read_user_parameters=1, water_ponding=0, KFICE=0, OPT_SNOW=2, OPT_FRAC=1,\n",
    "    OPT_LIQWAT=1, WAT_REDIS=0, save_minutes_csv=0, tperm=283.15,\n",
    "    user_wfcdp=0.32\n",
    ")\n",
    "\n",
    "\n",
    "# update the values per your case study\n",
    "dict_dates = {\n",
    "    \n",
    "    # The simulation start time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # must be the same or later than the first time-step inside the dataframe\n",
    "    # for the meteo dataframe. Empty string means it will use the first meteo\n",
    "    # time-step.\n",
    "    \"start_date\": \"\", \n",
    "    \n",
    "    # The simulation end time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # empty means model will run till the end of provided meteo data.\n",
    "    \"end_date\": \"\",\n",
    "    \n",
    "    # The end date of the spinup period (one day after it actually),\n",
    "    # in the following format: '2018-07-01 00:00:00'.\n",
    "    # Its time zone must be the site-local tz.\n",
    "    # Any daily aggregated data before this date is considered to be\n",
    "    # part of the spin-up period and will not be present in `dfdaily_out`\n",
    "    # attribute of the SVSModel instance.\n",
    "    # Provide an empty string in case there was no spinup period.\n",
    "    \"spinup_end_date\": \"2018-07-01 00:00:00\",\n",
    "    \n",
    "    # The local time zone of the case study (site). \n",
    "    # This will be used to convert `spinup_end_date` to a UTC datetime value.\n",
    "    \"time_zone\": \"America/Montreal\"\n",
    "}\n",
    "\n",
    "# If the model is going to go through a spin-up period, then the \n",
    "# default value of `auto` should be the choise. This means that some\n",
    "# reasonable values will be assigned to the state variables. \n",
    "# Otherwise, provide a dict with values for one or more of the state\n",
    "# variables you wish to set differently. (see docstring of ModelInputData)\n",
    "init_conds = \"auto\"\n",
    "\n",
    "# The name of the output csv file that contains the hourly output \n",
    "# variables. This file is located in the output folder of the model.   \n",
    "output_csvfile_name = 'svs1_soil_hourly.csv'\n",
    "\n",
    "# The name of the SVS executable file which is saved inside the model-run dir\n",
    "exec_file_name = 'SVS_exe' # add .exe if OS is Windows\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< main >>> --------------------------------------------------------------\n",
    "\n",
    "# An instance of ModelInputData\n",
    "# this object holds all the necessary info that are needed to create the\n",
    "# required SVS input files. \n",
    "l1_cover_input = ModelInputData(\n",
    "    work_dir_path=dict_path[\"work_dir\"], lyinfo_path=dict_path[\"cover_info\"], \n",
    "    metfile_path=dict_path[\"met_data\"], exec_file_path=dict_path[\"svs_exec\"],\n",
    "    host_dir_name=dict_path[\"host_folder_name\"],\n",
    "    \n",
    "    meteo_col_names=dict_met_col_labels, model_params=dict_model_params,\n",
    "    param_col_names=dict_param_col_labels,\n",
    "    \n",
    "    init_conds=init_conds,\n",
    "    \n",
    "    start_date=dict_dates[\"start_date\"],\n",
    "    end_date=dict_dates[\"end_date\"],\n",
    "    spinup_end_date=dict_dates[\"spinup_end_date\"],\n",
    "    time_zone=dict_dates[\"time_zone\"],\n",
    "    \n",
    "    output_csvfile_name=output_csvfile_name,\n",
    "    exec_file_name=exec_file_name\n",
    "    \n",
    ")\n",
    "\n",
    "# create an instance of SVSModel for the L1 cover\n",
    "single_svs_l1 = SVSModel(\n",
    "    required_data=l1_cover_input, remove_old_host_folder=True, verbose=True\n",
    ")\n",
    "\n",
    "# run the instance\n",
    "single_svs_l1.run_svs()\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< output >>> ------------------------------------------------------------\n",
    "\n",
    "if path_save := dict_path[\"save_results\"]:\n",
    "    single_svs_l1.dfdaily_out.to_csv(path_save, index=False)\n",
    "    \n",
    "print(\"\\nThe first five rows of the daily aggregated output\")\n",
    "single_svs_l1.dfdaily_out.head()\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74115d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T23:54:15.193377Z",
     "start_time": "2022-11-04T23:54:15.186754Z"
    }
   },
   "source": [
    "## L1 cover, SVS default parameters\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Run an instance of SVS model for the L1 cover, parameterized using the SVS estimated values for the <br>\n",
    "    soil properties.\n",
    "</p>\n",
    "<hr style=\"height:0.1vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaeb986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T00:36:15.418545Z",
     "start_time": "2022-11-09T00:36:06.282615Z"
    }
   },
   "outputs": [],
   "source": [
    "# <<< imports >>> -----------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from svs_model import SVSModel\n",
    "from prep_svs import ModelInputData\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< variable definition >>> -----------------------------------------------\n",
    "\n",
    "# the below-defined paths are relative to the current working dir before this\n",
    "# cell is run. It might be better to define all of them as absolute path. \n",
    "dict_path = {\n",
    "    # dir in which a folder will be created to host the SVS-run files\n",
    "    \"work_dir\": Path(\"./SVS\"),\n",
    "    \n",
    "    # path to the SVS executable file\n",
    "    \"svs_exec\": Path(\"./SVS/MESH_SVS_6p1\"),\n",
    "    \n",
    "    # path to the dataframe holding required info about the cover\n",
    "    \"cover_info\": Path(\"data/SVS/L1_params_SVSdefault.csv\"),\n",
    "    \n",
    "    # path to the dataframe holding hourly forcing variables\n",
    "    \"met_data\": Path(\"./data/SVS/hourly_SVS_meteo.csv\"),\n",
    "    \n",
    "    # name of the folder created inside `work_dir` to host SVS-run files\n",
    "    \"host_folder_name\": \"run_single_L1_SVSdef\", \n",
    "    \n",
    "    # provide a path here if you wish to save the daily output\n",
    "    \"save_results\": \"\" \n",
    "}\n",
    "\n",
    "# labels of the required columns in the meteo dataframe located at \n",
    "# `dict_path['met_data']`. \n",
    "# the required columns correspond to the required meteorological variables\n",
    "# needed to run SVS, plus the data-time column (tz: UTC)\n",
    "dict_met_col_labels = dict(\n",
    "    utc_dtime=\"dt_utc\", air_temperature=\"Air temperature (°C)\", \n",
    "    precipitation=\"Precipitation (mm)\", wind_speed=\"Wind speed (m.s-1)\", \n",
    "    atmospheric_pressure=\"Atmospheric pressure (Pa)\", \n",
    "    shortwave_radiation=\"Shortwave radiation (W.m-2)\", \n",
    "    longwave_radiation=\"Longwave radiation (W.m-2)\", \n",
    "    specific_humidity=\"Specific humidity (kg.kg-1)\",\n",
    "    relative_humidity=\"Relative humidity (%)\" # needed only for precip phase \n",
    ")\n",
    "\n",
    "# The label of the columns, inside the dataframe holding the cover's info\n",
    "# located at `dict_path['cover_info']`, corresponding to the parameters that\n",
    "# are required to create the MESH_parameters.txt file. \n",
    "# e.g. the values for the `sand` parameter in the MESH_parameters.txt file is \n",
    "# stored in a column named `sand` in the dataframe\n",
    "dict_param_col_labels = dict(\n",
    "    # parameters for each soil layer\n",
    "    sand=\"sand\", clay=\"clay\", wsat=\"Wsat\", wfc=\"Wfc\", wwilt=\"Wwilt\",\n",
    "    psisat=\"Psi_sat\", bcoef=\"bcoef\", ksat=\"Ksat\", rhosoil=\"dry_density\",\n",
    "    \n",
    "    # scalar parameters\n",
    "    slop=\"enclosure_slope\", observed_forcing=\"observed_forcing\", zusl=\"zusl\",\n",
    "    ztsl=\"ztsl\", deglat=\"deglat\", deglng=\"deglng\", vf_type=\"vf_type\",\n",
    "    draindens=\"draindens\"\n",
    ") \n",
    "\n",
    "# The values for some of the model parameters that are read from\n",
    "# the MESH_parameters.txt file. \n",
    "dict_model_params = dict(\n",
    "    SCHMSOL=\"SVS\", lsoil_freezing_svs1=\".true.\", soiltext=\"NIL\",\n",
    "    read_user_parameters=1, water_ponding=0, KFICE=0, OPT_SNOW=2, OPT_FRAC=1,\n",
    "    OPT_LIQWAT=1, WAT_REDIS=0, save_minutes_csv=0, tperm=283.15,\n",
    "    user_wfcdp=0.32\n",
    ")\n",
    "\n",
    "# update the values per your case study\n",
    "dict_dates = {\n",
    "    \n",
    "    # The simulation start time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # must be the same or later than the first time-step inside the dataframe\n",
    "    # for the meteo dataframe. Empty string means it will use the first meteo\n",
    "    # time-step.\n",
    "    \"start_date\": \"\", \n",
    "    \n",
    "    # The simulation end time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # empty means model will run till the end of provided meteo data.\n",
    "    \"end_date\": \"\",\n",
    "    \n",
    "    # The end date of the spinup period (one day after it actually),\n",
    "    # in the following format: '2018-07-01 00:00:00'.\n",
    "    # Its time zone must be the site-local tz.\n",
    "    # Any daily aggregated data before this date is considered to be\n",
    "    # part of the spin-up period and will not be present in `dfdaily_out`\n",
    "    # attribute of the SVSModel instance.\n",
    "    # Provide an empty string in case there was no spinup period.\n",
    "    \"spinup_end_date\": \"2018-07-01 00:00:00\",\n",
    "    \n",
    "    # The local time zone of the case study (site). \n",
    "    # This will be used to convert `spinup_end_date` to a UTC datetime value.\n",
    "    \"time_zone\": \"America/Montreal\"\n",
    "}\n",
    "\n",
    "# If the model is going to go through a spin-up period, then the \n",
    "# default value of `auto` should be the choise. This means that some\n",
    "# reasonable values will be assigned to the state variables. \n",
    "# Otherwise, provide a dict with values for one or more of the state\n",
    "# variables you wish to set differently. (see docstring of ModelInputData)\n",
    "init_conds = \"auto\"\n",
    "\n",
    "# The name of the output csv file that contains the hourly output \n",
    "# variables. This file is located in the output folder of the model.   \n",
    "output_csvfile_name = 'svs1_soil_hourly.csv'\n",
    "\n",
    "# The name of the SVS executable file which is saved inside the model-run dir\n",
    "exec_file_name = 'SVS_exe' # add .exe if OS is Windows\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< main >>> --------------------------------------------------------------\n",
    "\n",
    "# An instance of ModelInputData\n",
    "# this object holds all the necessary info that are needed to create the\n",
    "# required SVS input files. \n",
    "l1_cover_input = ModelInputData(\n",
    "    work_dir_path=dict_path[\"work_dir\"], lyinfo_path=dict_path[\"cover_info\"], \n",
    "    metfile_path=dict_path[\"met_data\"], exec_file_path=dict_path[\"svs_exec\"],\n",
    "    host_dir_name=dict_path[\"host_folder_name\"],\n",
    "    \n",
    "    meteo_col_names=dict_met_col_labels, model_params=dict_model_params,\n",
    "    param_col_names=dict_param_col_labels,\n",
    "    \n",
    "    init_conds=init_conds,\n",
    "    \n",
    "    start_date=dict_dates[\"start_date\"],\n",
    "    end_date=dict_dates[\"end_date\"],\n",
    "    spinup_end_date=dict_dates[\"spinup_end_date\"],\n",
    "    time_zone=dict_dates[\"time_zone\"],\n",
    "    \n",
    "    output_csvfile_name=output_csvfile_name,\n",
    "    exec_file_name=exec_file_name\n",
    "    \n",
    ")\n",
    "\n",
    "# create an instance of SVSModel for the L1 cover\n",
    "single_svs_l1 = SVSModel(\n",
    "    required_data=l1_cover_input, remove_old_host_folder=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# run the instance\n",
    "single_svs_l1.run_svs()\n",
    "\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< output >>> ------------------------------------------------------------\n",
    "\n",
    "if path_save := dict_path[\"save_results\"]:\n",
    "    single_svs_l1.dfdaily_out.to_csv(path_save, index=False)\n",
    "\n",
    "print(\"\\nThe first five rows of the daily aggregated output\")\n",
    "single_svs_l1.dfdaily_out.head()\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2cc66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T23:38:29.523288Z",
     "start_time": "2022-11-04T23:38:29.518852Z"
    }
   },
   "source": [
    "# Run an ensemble of SVS models\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Create and run ensembles of SVS model for the soil covers presented in the manuscript\n",
    "</p>\n",
    "<hr style=\"height:0.3vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df622b9e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## L1 cover, laboratory parameters\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Create and run an ensemble of SVS models for the L1 cover, parameterized using the laboratory-obtained values for the <br>\n",
    "    soil properties.<br>\n",
    "    The ensemble is created by using different values for the trigger moisture. \n",
    "</p>\n",
    "<hr style=\"height:0.1vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47403b05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T01:07:48.623101Z",
     "start_time": "2022-11-06T01:00:58.480566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# <<< imports >>> -----------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from prep_svs import ModelInputData\n",
    "from perturb_run import PerturbAndRun\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< variable definition >>> -----------------------------------------------\n",
    "\n",
    "# the below-defined paths are relative to the current working dir before this\n",
    "# cell is run. It might be better to define all of them as absolute path. \n",
    "dict_path = {\n",
    "    # existing dir in which a folder will be created to host the SVS-run files\n",
    "    \"work_dir\": Path(\"./SVS/L1_svslab_wfcdp_100ensembles/\"),\n",
    "    \n",
    "    # path to the SVS executable file\n",
    "    \"svs_exec\": Path(\"./SVS/MESH_SVS_6p1\"),\n",
    "    \n",
    "    # path to the dataframe holding required info about the cover\n",
    "    \"cover_info\": Path(\"data/SVS/L1_params.csv\"),\n",
    "    \n",
    "    # path to the dataframe holding hourly forcing variables\n",
    "    \"met_data\": Path(\"./data/SVS/hourly_SVS_meteo.csv\"),\n",
    "    \n",
    "    # no need to set this for creating ensembles\n",
    "    \"host_folder_name\": \"place_holder\",\n",
    "    \n",
    "    # provide a path here if you wish to save the daily output\n",
    "    \"save_results\": \"\" \n",
    "}\n",
    "\n",
    "# labels of the required columns in the meteo dataframe located at \n",
    "# `dict_path['met_data']`. \n",
    "# the required columns correspond to the required meteorological variables\n",
    "# needed to run SVS, plus the data-time column (tz: UTC)\n",
    "dict_met_col_labels = dict(\n",
    "    utc_dtime=\"dt_utc\", air_temperature=\"Air temperature (°C)\", \n",
    "    precipitation=\"Precipitation (mm)\", wind_speed=\"Wind speed (m.s-1)\", \n",
    "    atmospheric_pressure=\"Atmospheric pressure (Pa)\", \n",
    "    shortwave_radiation=\"Shortwave radiation (W.m-2)\", \n",
    "    longwave_radiation=\"Longwave radiation (W.m-2)\", \n",
    "    specific_humidity=\"Specific humidity (kg.kg-1)\",\n",
    "    relative_humidity=\"Relative humidity (%)\" # needed only for precip phase \n",
    ")\n",
    "\n",
    "# The label of the columns, inside the dataframe holding the cover's info\n",
    "# located at `dict_path['cover_info']`, corresponding to the parameters that\n",
    "# are required to create the MESH_parameters.txt file. \n",
    "# e.g. the values for the `sand` parameter in the MESH_parameters.txt file is \n",
    "# stored in a column named `sand` in the dataframe\n",
    "dict_param_col_labels = dict(\n",
    "    # parameters for each soil layer\n",
    "    sand=\"sand\", clay=\"clay\", wsat=\"Wsat\", wfc=\"Wfc\", wwilt=\"Wwilt\",\n",
    "    psisat=\"Psi_sat\", bcoef=\"bcoef\", ksat=\"Ksat\", rhosoil=\"dry_density\",\n",
    "    \n",
    "    # scalar parameters\n",
    "    slop=\"enclosure_slope\", observed_forcing=\"observed_forcing\", zusl=\"zusl\",\n",
    "    ztsl=\"ztsl\", deglat=\"deglat\", deglng=\"deglng\", vf_type=\"vf_type\",\n",
    "    draindens=\"draindens\"\n",
    ") \n",
    "\n",
    "# The values for some of the model parameters that are read from\n",
    "# the MESH_parameters.txt file. \n",
    "dict_model_params = dict(\n",
    "    SCHMSOL=\"SVS\", lsoil_freezing_svs1=\".true.\", soiltext=\"NIL\",\n",
    "    read_user_parameters=1, water_ponding=0, KFICE=0, OPT_SNOW=2, OPT_FRAC=1,\n",
    "    OPT_LIQWAT=1, WAT_REDIS=0, save_minutes_csv=0, tperm=283.15,\n",
    "    user_wfcdp=0.32\n",
    ")\n",
    "\n",
    "# ensemble settings for the `user_wfcdp` parameter, i.e. the trigger moisture\n",
    "dict_ens_setting = {\n",
    "    \"lower_bound\": 0.0579, # wfc of the last layer\n",
    "    \"upper_bound\": 0.3260, # wsat of the last layer (an eps smaller)\n",
    "    \"ens_size\": 100,\n",
    "    \"round_decimals\": 4, # round values to 4 decimals \n",
    "    \n",
    "    \"n_cpu_cores\": 4 # number of CPU cores to use for the parallel run\n",
    "}\n",
    "\n",
    "# hold the parameter values\n",
    "dict_parameter_scenarios = dict()\n",
    "\n",
    "# update the values per your case study\n",
    "dict_dates = {\n",
    "    \n",
    "    # The simulation start time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # must be the same or later than the first time-step inside the dataframe\n",
    "    # for the meteo dataframe. Empty string means it will use the first meteo\n",
    "    # time-step.\n",
    "    \"start_date\": \"\", \n",
    "    \n",
    "    # The simulation end time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # empty means model will run till the end of provided meteo data.\n",
    "    \"end_date\": \"\",\n",
    "    \n",
    "    # The end date of the spinup period (one day after it actually),\n",
    "    # in the following format: '2018-07-01 00:00:00'.\n",
    "    # Its time zone must be the site-local tz.\n",
    "    # Any daily aggregated data before this date is considered to be\n",
    "    # part of the spin-up period and will not be present in `dfdaily_out`\n",
    "    # attribute of the SVSModel instance.\n",
    "    # Provide an empty string in case there was no spinup period.\n",
    "    \"spinup_end_date\": \"2018-07-01 00:00:00\",\n",
    "    \n",
    "    # The local time zone of the case study (site). \n",
    "    # This will be used to convert `spinup_end_date` to a UTC datetime value.\n",
    "    \"time_zone\": \"America/Montreal\"\n",
    "}\n",
    "\n",
    "# If the model is going to go through a spin-up period, then the \n",
    "# default value of `auto` should be the choise. This means that some\n",
    "# reasonable values will be assigned to the state variables. \n",
    "# Otherwise, provide a dict with values for one or more of the state\n",
    "# variables you wish to set differently. (see docstring of ModelInputData)\n",
    "init_conds = \"auto\"\n",
    "\n",
    "# The name of the output csv file that contains the hourly output \n",
    "# variables. This file is located in the output folder of the model.   \n",
    "output_csvfile_name = 'svs1_soil_hourly.csv'\n",
    "\n",
    "\n",
    "# The name of the SVS executable file which is saved inside the model-run dir\n",
    "exec_file_name = 'SVS_exe' # add .exe if OS is Windows\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< main >>> --------------------------------------------------------------\n",
    "\n",
    "# An instance of ModelInputData\n",
    "# this object holds all the necessary info that are needed to create the\n",
    "# required SVS input files. \n",
    "l1_cover_input = ModelInputData(\n",
    "    work_dir_path=dict_path[\"work_dir\"], lyinfo_path=dict_path[\"cover_info\"], \n",
    "    metfile_path=dict_path[\"met_data\"], exec_file_path=dict_path[\"svs_exec\"],\n",
    "    host_dir_name=dict_path[\"host_folder_name\"],\n",
    "    \n",
    "    meteo_col_names=dict_met_col_labels, model_params=dict_model_params,\n",
    "    param_col_names=dict_param_col_labels,\n",
    "    \n",
    "    init_conds=init_conds,\n",
    "    \n",
    "    start_date=dict_dates[\"start_date\"],\n",
    "    end_date=dict_dates[\"end_date\"],\n",
    "    spinup_end_date=dict_dates[\"spinup_end_date\"],\n",
    "    time_zone=dict_dates[\"time_zone\"],\n",
    "    \n",
    "    output_csvfile_name=output_csvfile_name,\n",
    "    exec_file_name=exec_file_name\n",
    "    \n",
    ")\n",
    "\n",
    "# perturb `user_wfcdp` between wfc and wsat of the last layer\n",
    "wfcdp_values = np.round(np.linspace(\n",
    "    start=dict_ens_setting[\"lower_bound\"],\n",
    "    stop=dict_ens_setting[\"upper_bound\"],\n",
    "    num=dict_ens_setting[\"ens_size\"], endpoint=True\n",
    "), dict_ens_setting[\"round_decimals\"])\n",
    "\n",
    "# store the values\n",
    "for i1, value in enumerate(wfcdp_values):\n",
    "    dict_parameter_scenarios[F\"member_{i1}\"] = dict(user_wfcdp=value)\n",
    "\n",
    "# create the ensemble and run them in parallel\n",
    "perturb_wfcdp_l1 = PerturbAndRun(\n",
    "    svs_default_input=l1_cover_input,\n",
    "    parameter_scenarios=dict_parameter_scenarios,\n",
    "    njobs=dict_ens_setting[\"n_cpu_cores\"]\n",
    ")\n",
    "\n",
    "# save the retruned object, i.e. the daily outputs as a dataframe\n",
    "output_dataframe = perturb_wfcdp_l1.run_all_parallel()\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< output >>> ------------------------------------------------------------\n",
    "\n",
    "if path_save := dict_path[\"save_results\"]:\n",
    "    output_dataframe.to_csv(path_save, index=False)\n",
    "    \n",
    "print(\"\\nThe first five rows of the daily aggregated output\")\n",
    "output_dataframe.head()\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee057b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T02:05:11.568269Z",
     "start_time": "2022-11-05T02:05:11.563233Z"
    }
   },
   "source": [
    "## L1 cover, SVS default parameters\n",
    "<br>\n",
    "<p style=\"font-size: 1.2em\">\n",
    "    Create and run an ensemble of SVS models for the L1 cover, parameterized using the SVS-estimated values for the <br>\n",
    "    soil properties.<br>\n",
    "    The ensemble is created by using different values for the trigger moisture. \n",
    "</p>\n",
    "<hr style=\"height:0.1vw\">\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63318132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T00:37:51.905541Z",
     "start_time": "2022-11-09T00:37:28.554168Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An SVS instance successfully created!\n",
      "\n",
      "the SVS instance modified based on scenario member_0.\n",
      "\n",
      "An SVS instance successfully created!\n",
      "\n",
      "the SVS instance modified based on scenario member_1.\n",
      "\n",
      "An SVS instance successfully created!\n",
      "\n",
      "the SVS instance modified based on scenario member_2.\n",
      "\n",
      "Running member_0 SVS instance ...\n",
      "\n",
      "Running member_1 SVS instance ...\n",
      "\n",
      "Waiting for the 2 processes to finish ...\n",
      "Finished!\n",
      "\n",
      "Running member_2 SVS instance ...\n",
      "\n",
      "Waiting for the last 1 processe(s) to finish ...\n",
      "Finished!\n",
      "\n",
      "\n",
      "The first five rows of the daily aggregated output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRAI</th>\n",
       "      <th>ET</th>\n",
       "      <th>PCP</th>\n",
       "      <th>OVFLW</th>\n",
       "      <th>date</th>\n",
       "      <th>WSOIL_1</th>\n",
       "      <th>WSOIL_2</th>\n",
       "      <th>WSOIL_3</th>\n",
       "      <th>WSOIL_4</th>\n",
       "      <th>WSOIL_5</th>\n",
       "      <th>...</th>\n",
       "      <th>TSNO_1</th>\n",
       "      <th>TSNO_2</th>\n",
       "      <th>SNVMA</th>\n",
       "      <th>SNVDP</th>\n",
       "      <th>SNVDEN</th>\n",
       "      <th>SNVALB</th>\n",
       "      <th>WSNV</th>\n",
       "      <th>TSNV_1</th>\n",
       "      <th>TSNV_2</th>\n",
       "      <th>member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049353</td>\n",
       "      <td>1.380834</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.198948</td>\n",
       "      <td>0.195070</td>\n",
       "      <td>0.187431</td>\n",
       "      <td>0.171165</td>\n",
       "      <td>0.165005</td>\n",
       "      <td>...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>member_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050812</td>\n",
       "      <td>4.029015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>0.172460</td>\n",
       "      <td>0.177139</td>\n",
       "      <td>0.176045</td>\n",
       "      <td>0.170259</td>\n",
       "      <td>...</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>member_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049839</td>\n",
       "      <td>3.671327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>0.132635</td>\n",
       "      <td>0.153064</td>\n",
       "      <td>0.162319</td>\n",
       "      <td>0.169134</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>...</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>member_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047165</td>\n",
       "      <td>3.335324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>0.113449</td>\n",
       "      <td>0.141940</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.162684</td>\n",
       "      <td>0.163171</td>\n",
       "      <td>...</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>member_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043761</td>\n",
       "      <td>3.457620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>0.095609</td>\n",
       "      <td>0.135485</td>\n",
       "      <td>0.147582</td>\n",
       "      <td>0.157373</td>\n",
       "      <td>0.158745</td>\n",
       "      <td>...</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.5</td>\n",
       "      <td>287.5</td>\n",
       "      <td>member_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DRAI        ET  PCP  OVFLW        date   WSOIL_1   WSOIL_2   WSOIL_3  \\\n",
       "0  0.049353  1.380834  5.2    0.0  2017-07-01  0.198948  0.195070  0.187431   \n",
       "1  0.050812  4.029015  0.0    0.0  2017-07-02  0.162417  0.172460  0.177139   \n",
       "2  0.049839  3.671327  0.0    0.0  2017-07-03  0.132635  0.153064  0.162319   \n",
       "3  0.047165  3.335324  0.0    0.0  2017-07-04  0.113449  0.141940  0.153530   \n",
       "4  0.043761  3.457620  0.0    0.0  2017-07-05  0.095609  0.135485  0.147582   \n",
       "\n",
       "    WSOIL_4   WSOIL_5  ...  TSNO_1  TSNO_2  SNVMA  SNVDP  SNVDEN  SNVALB  \\\n",
       "0  0.171165  0.165005  ...   275.0   275.0    0.0    0.0   150.0     0.8   \n",
       "1  0.176045  0.170259  ...   287.5   287.5    0.0    0.0   150.0     0.8   \n",
       "2  0.169134  0.167623  ...   287.5   287.5    0.0    0.0   150.0     0.8   \n",
       "3  0.162684  0.163171  ...   287.5   287.5    0.0    0.0   150.0     0.8   \n",
       "4  0.157373  0.158745  ...   287.5   287.5    0.0    0.0   150.0     0.8   \n",
       "\n",
       "   WSNV  TSNV_1  TSNV_2    member  \n",
       "0   0.0   275.0   275.0  member_0  \n",
       "1   0.0   287.5   287.5  member_0  \n",
       "2   0.0   287.5   287.5  member_0  \n",
       "3   0.0   287.5   287.5  member_0  \n",
       "4   0.0   287.5   287.5  member_0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <<< imports >>> -----------------------------------------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from prep_svs import ModelInputData\n",
    "from perturb_run import PerturbAndRun\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< variable definition >>> -----------------------------------------------\n",
    "\n",
    "# the below-defined paths are relative to the current working dir before this\n",
    "# cell is run. It might be better to define all of them as absolute path. \n",
    "dict_path = {\n",
    "    # existing dir in which a folder will be created to host the SVS-run files\n",
    "    \"work_dir\": Path(\"./SVS/L1_svsdef_wfcdp_100ensembles/\"),\n",
    "    \n",
    "    # path to the SVS executable file\n",
    "    \"svs_exec\": Path(\"./SVS/MESH_SVS_6p1\"),\n",
    "    \n",
    "    # path to the dataframe holding required info about the cover\n",
    "    \"cover_info\": Path(\"data/SVS/L1_params_SVSdefault.csv\"),\n",
    "    \n",
    "    # path to the dataframe holding hourly forcing variables\n",
    "    \"met_data\": Path(\"./data/SVS/hourly_SVS_meteo.csv\"),\n",
    "    \n",
    "    # no need to set this for creating ensembles\n",
    "    \"host_folder_name\": \"place_holder\",\n",
    "    \n",
    "    # provide a path here if you wish to save the daily output\n",
    "    \"save_results\": \"./results.csv\"  # change this\n",
    "}\n",
    "\n",
    "# labels of the required columns in the meteo dataframe located at \n",
    "# `dict_path['met_data']`. \n",
    "# the required columns correspond to the required meteorological variables\n",
    "# needed to run SVS, plus the data-time column (tz: UTC)\n",
    "dict_met_col_labels = dict(\n",
    "    utc_dtime=\"dt_utc\", air_temperature=\"Air temperature (°C)\", \n",
    "    precipitation=\"Precipitation (mm)\", wind_speed=\"Wind speed (m.s-1)\", \n",
    "    atmospheric_pressure=\"Atmospheric pressure (Pa)\", \n",
    "    shortwave_radiation=\"Shortwave radiation (W.m-2)\", \n",
    "    longwave_radiation=\"Longwave radiation (W.m-2)\", \n",
    "    specific_humidity=\"Specific humidity (kg.kg-1)\",\n",
    "    relative_humidity=\"Relative humidity (%)\" # needed only for precip phase \n",
    ")\n",
    "\n",
    "# The label of the columns, inside the dataframe holding the cover's info\n",
    "# located at `dict_path['cover_info']`, corresponding to the parameters that\n",
    "# are required to create the MESH_parameters.txt file. \n",
    "# e.g. the values for the `sand` parameter in the MESH_parameters.txt file is \n",
    "# stored in a column named `sand` in the dataframe\n",
    "dict_param_col_labels = dict(\n",
    "    # parameters for each soil layer\n",
    "    sand=\"sand\", clay=\"clay\", wsat=\"Wsat\", wfc=\"Wfc\", wwilt=\"Wwilt\",\n",
    "    psisat=\"Psi_sat\", bcoef=\"bcoef\", ksat=\"Ksat\", rhosoil=\"dry_density\",\n",
    "    \n",
    "    # scalar parameters\n",
    "    slop=\"enclosure_slope\", observed_forcing=\"observed_forcing\", zusl=\"zusl\",\n",
    "    ztsl=\"ztsl\", deglat=\"deglat\", deglng=\"deglng\", vf_type=\"vf_type\",\n",
    "    draindens=\"draindens\"\n",
    ") \n",
    "\n",
    "# The values for some of the model parameters that are read from\n",
    "# the MESH_parameters.txt file. \n",
    "dict_model_params = dict(\n",
    "    SCHMSOL=\"SVS\", lsoil_freezing_svs1=\".true.\", soiltext=\"NIL\",\n",
    "    read_user_parameters=1, water_ponding=0, KFICE=0, OPT_SNOW=2, OPT_FRAC=1,\n",
    "    OPT_LIQWAT=1, WAT_REDIS=0, save_minutes_csv=0, tperm=283.15,\n",
    "    user_wfcdp=0.32\n",
    ")\n",
    "\n",
    "# ensemble settings for the `user_wfcdp` parameter, i.e. the trigger moisture\n",
    "dict_ens_setting = {\n",
    "    \"lower_bound\": 0.1625, # wfc of the last layer\n",
    "    \"upper_bound\": 0.389, # wsat of the last layer (an eps smaller)\n",
    "    \"ens_size\": 100,\n",
    "    \"round_decimals\": 4, # round values to 4 decimals \n",
    "    \n",
    "    \"n_cpu_cores\": 2 # number of CPU cores to use for the parallel run\n",
    "}\n",
    "\n",
    "# hold the parameter values\n",
    "dict_parameter_scenarios = dict()\n",
    "\n",
    "# update the values per your case study\n",
    "dict_dates = {\n",
    "    \n",
    "    # The simulation start time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # must be the same or later than the first time-step inside the dataframe\n",
    "    # for the meteo dataframe. Empty string means it will use the first meteo\n",
    "    # time-step.\n",
    "    \"start_date\": \"\", \n",
    "    \n",
    "    # The simulation end time step; provide it as: `YYYY-JDAY-HH-MM`\n",
    "    # empty means model will run till the end of provided meteo data.\n",
    "    \"end_date\": \"\",\n",
    "    \n",
    "    # The end date of the spinup period (one day after it actually),\n",
    "    # in the following format: '2018-07-01 00:00:00'.\n",
    "    # Its time zone must be the site-local tz.\n",
    "    # Any daily aggregated data before this date is considered to be\n",
    "    # part of the spin-up period and will not be present in `dfdaily_out`\n",
    "    # attribute of the SVSModel instance.\n",
    "    # Provide an empty string in case there was no spinup period.\n",
    "    \"spinup_end_date\": \"2018-07-01 00:00:00\",\n",
    "    \n",
    "    # The local time zone of the case study (site). \n",
    "    # This will be used to convert `spinup_end_date` to a UTC datetime value.\n",
    "    \"time_zone\": \"America/Montreal\"\n",
    "}\n",
    "\n",
    "# If the model is going to go through a spin-up period, then the \n",
    "# default value of `auto` should be the choise. This means that some\n",
    "# reasonable values will be assigned to the state variables. \n",
    "# Otherwise, provide a dict with values for one or more of the state\n",
    "# variables you wish to set differently. (see docstring of ModelInputData)\n",
    "init_conds = \"auto\"\n",
    "\n",
    "# The name of the output csv file that contains the hourly output \n",
    "# variables. This file is located in the output folder of the model.   \n",
    "output_csvfile_name = 'svs1_soil_hourly.csv'\n",
    "\n",
    "# The name of the SVS executable file which is saved inside the model-run dir\n",
    "exec_file_name = 'SVS_exe' # add .exe if OS is Windows\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< main >>> --------------------------------------------------------------\n",
    "\n",
    "# An instance of ModelInputData\n",
    "# this object holds all the necessary info that are needed to create the\n",
    "# required SVS input files. \n",
    "l1_cover_input = ModelInputData(\n",
    "    work_dir_path=dict_path[\"work_dir\"], lyinfo_path=dict_path[\"cover_info\"], \n",
    "    metfile_path=dict_path[\"met_data\"], exec_file_path=dict_path[\"svs_exec\"],\n",
    "    host_dir_name=dict_path[\"host_folder_name\"],\n",
    "    \n",
    "    meteo_col_names=dict_met_col_labels, model_params=dict_model_params,\n",
    "    param_col_names=dict_param_col_labels,\n",
    "    \n",
    "    init_conds=init_conds,\n",
    "    \n",
    "    start_date=dict_dates[\"start_date\"],\n",
    "    end_date=dict_dates[\"end_date\"],\n",
    "    spinup_end_date=dict_dates[\"spinup_end_date\"],\n",
    "    time_zone=dict_dates[\"time_zone\"],\n",
    "    \n",
    "    output_csvfile_name=output_csvfile_name,\n",
    "    exec_file_name=exec_file_name\n",
    "    \n",
    ")\n",
    "\n",
    "# perturb `user_wfcdp` between wfc and wsat of the last layer\n",
    "wfcdp_values = np.round(np.linspace(\n",
    "    start=dict_ens_setting[\"lower_bound\"],\n",
    "    stop=dict_ens_setting[\"upper_bound\"],\n",
    "    num=dict_ens_setting[\"ens_size\"], endpoint=True\n",
    "), dict_ens_setting[\"round_decimals\"])\n",
    "\n",
    "# store the values\n",
    "for i1, value in enumerate(wfcdp_values):\n",
    "    dict_parameter_scenarios[F\"member_{i1}\"] = dict(user_wfcdp=value)\n",
    "\n",
    "# create the ensemble and run them in parallel\n",
    "perturb_wfcdp_l1 = PerturbAndRun(\n",
    "    svs_default_input=l1_cover_input,\n",
    "    parameter_scenarios=dict_parameter_scenarios,\n",
    "    njobs=dict_ens_setting[\"n_cpu_cores\"]\n",
    ")\n",
    "\n",
    "# save the retruned object, i.e. the daily outputs as a dataframe\n",
    "output_dataframe = perturb_wfcdp_l1.run_all_parallel()\n",
    "# ___________________________________________________________________ <<< >>>\n",
    "\n",
    "# <<< output >>> ------------------------------------------------------------\n",
    "\n",
    "if path_save := dict_path[\"save_results\"]:\n",
    "    output_dataframe.to_csv(path_save, index=False)\n",
    "    \n",
    "print(\"\\nThe first five rows of the daily aggregated output\")\n",
    "output_dataframe.head()\n",
    "# ___________________________________________________________________ <<< >>>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
